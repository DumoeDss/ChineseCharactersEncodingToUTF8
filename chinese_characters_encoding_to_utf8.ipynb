{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符编码转utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install django\n",
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "# 语料TXT文本编码转换为UTF8  - 作者：i126@126.com \n",
    "# https://github.com/adetion/txtfilemerge\n",
    "# modify by sayo with chatgpt\n",
    "########################################################################################################\n",
    "import chardet\n",
    "import codecs\n",
    "import os\n",
    "from django.utils.encoding import force_str\n",
    "from django.utils.functional import Promise\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def allpath_txt_encoding_to_utf8(input_path, output_path, file_ext=('.txt', '.csv')):\n",
    "    \"\"\"\n",
    "    某目录下(含子目录)所有文本文件编码格式全部转为UTF-8\n",
    "    传入参数：输入路径和输出路径。也可为绝对路径（windows可能会有BUG）\n",
    "    \"\"\"\n",
    "    for dirpath, _, filenames in os.walk(input_path):\n",
    "        for filename in filenames:\n",
    "            try:\n",
    "                if os.path.splitext(filename)[1].lower() in file_ext:\n",
    "                    full_input_path = os.path.join(dirpath, filename)\n",
    "                    \n",
    "                    relative_path = os.path.relpath(full_input_path, input_path)\n",
    "                    \n",
    "                    full_output_path = os.path.join(output_path, relative_path)\n",
    "                    \n",
    "                    file_txt_encoding_to_utf8(full_input_path, full_output_path)\n",
    "            except Exception as ERR:\n",
    "                print('Error:', ERR)\n",
    "\n",
    "def path_txt_encoding_to_utf8(input_path, output_path, file_ext=('.txt', '.csv')):\n",
    "    \"\"\"\n",
    "    某目录下（不含子目录）所有文本文件编码格式全部转为UTF-8\n",
    "    传入参数：输入路径和输出路径。也可为绝对路径（windows可能会有BUG）\n",
    "    \"\"\"\n",
    "    dis = os.listdir(input_path)\n",
    "    for filename in dis:\n",
    "        try:\n",
    "            if os.path.splitext(filename)[1].lower() in file_ext:\n",
    "                full_input_path = os.path.join(input_path, filename)\n",
    "                full_output_path = os.path.join(output_path, filename)\n",
    "                \n",
    "                file_txt_encoding_to_utf8(full_input_path, full_output_path)\n",
    "        except Exception as ERR:\n",
    "            print('Error:', ERR)\n",
    "\n",
    "def file_txt_encoding_to_utf8(input_file, output_file, file_ext=('.txt', '.csv')):\n",
    "    if os.path.splitext(input_file)[1].lower() in file_ext:\n",
    "        f_type = check_file_charset(input_file)\n",
    "        print(input_file, \"字符集为：\", f_type['encoding'])\n",
    "        output_dir = os.path.dirname(output_file)\n",
    "        Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            if f_type and 'encoding' in f_type.keys() and f_type['encoding'] != 'utf-8':\n",
    "                with codecs.open(input_file, 'rb', f_type['encoding'], errors='ignore') as f:\n",
    "                    content = smart_str(f.read())\n",
    "                \n",
    "                with codecs.open(output_file, 'w', 'utf-8') as f:\n",
    "                    f.write(content)\n",
    "                print(\"字符集转换成功：自动\")\n",
    "            else:\n",
    "                shutil.copy2(input_file, output_file)\n",
    "                print(\"字符集为 utf-8，不需要进行转换\")\n",
    "        except Exception as ERR:\n",
    "            try:\n",
    "                content = codecs.open(input_file, 'rb', encoding='gbk').read()\n",
    "                \n",
    "                with codecs.open(output_file, 'w', 'utf-8') as f:\n",
    "                    f.write(content)\n",
    "                print(\"字符集转换成功：GBK --> UTF-8\")\n",
    "            except Exception as ERR1:\n",
    "                try:\n",
    "                    content = codecs.open(input_file, 'rb', encoding='gb18030', errors='ignore').read()\n",
    "                    \n",
    "                    with codecs.open(output_file, 'w', 'utf-8') as f:\n",
    "                        f.write(content)\n",
    "                    print(\"字符集转换成功：gb18030 --> UTF-8\")\n",
    "                except Exception as ERR2:\n",
    "                        try:\n",
    "                            content = codecs.open(input_file, 'rb', encoding='big5').read()\n",
    "\n",
    "                            with codecs.open(output_file, 'w', 'utf-8') as f:\n",
    "                                f.write(content)\n",
    "                            print(\"字符集转换成功：big5 --> UTF-8\")\n",
    "                        except Exception as ERR3:\n",
    "                            print('error ERR3')\n",
    "                            pass\n",
    "    else:\n",
    "        print(input_file, '文件(扩展名)不在允许转换范围内...')\n",
    "        pass\n",
    "\n",
    "\n",
    "def check_file_charset(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return chardet.detect(f.read()[0:1024])\n",
    "\n",
    "def smart_str(s, encoding=\"utf-8\", strings_only=False, errors=\"strict\"):\n",
    "    \"\"\"\n",
    "    返回表示“s”的字符串。使用“encoding”处理字节字符串编解码器。\n",
    "    如果strings_only为True，则不转换（某些）非字符串类对象。\n",
    "    \"\"\"\n",
    "    if isinstance(s, Promise):\n",
    "        return s\n",
    "    return force_str(s, encoding, strings_only, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建议使用的多线程/多进程版本\n",
    "input_path = \"origin\"\n",
    "output_path = \"utf-8\"\n",
    "allpath_txt_encoding_to_utf8(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多线程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "import os\n",
    "\n",
    "class FileProcessor:\n",
    "    \n",
    "    def __init__(self, input_path, output_path):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.file_queue = queue.Queue()\n",
    "    \n",
    "    def get_all_files(self, new_ext = None):\n",
    "        for dirpath, _, filenames in os.walk(self.input_path):\n",
    "            for filename in filenames:\n",
    "                full_input_path = os.path.join(dirpath, filename)\n",
    "                relative_path = os.path.relpath(full_input_path, self.input_path)\n",
    "                if new_ext is not None and new_ext != \"\":\n",
    "                    root, _ = os.path.splitext(relative_path)\n",
    "                    full_output_path = os.path.join(self.output_path, root + new_ext)\n",
    "                else:\n",
    "                    full_output_path = os.path.join(self.output_path, relative_path)\n",
    "                self.file_queue.put((full_input_path, full_output_path))\n",
    "    \n",
    "    def process_file(self, input_path, output_path, file_ext='.txt|.csv'):\n",
    "        pass\n",
    "    \n",
    "    def worker(self):\n",
    "        while not self.file_queue.empty():\n",
    "            input_file_path, output_file_path = self.file_queue.get()\n",
    "            try:\n",
    "                self.process_file(input_file_path, output_file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {input_file_path}: {str(e)}\")\n",
    "            finally:\n",
    "                self.file_queue.task_done()\n",
    "    \n",
    "    def process_files_multithreaded(self, num_threads, new_ext=None):\n",
    "        self.get_all_files(new_ext)\n",
    "        \n",
    "        threads = []\n",
    "        for _ in range(num_threads):\n",
    "            t = threading.Thread(target=self.worker)\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "        \n",
    "        self.file_queue.join()\n",
    "        \n",
    "        for t in threads:\n",
    "            t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线程数根据cpu线程数定，使用多进程版本更快\n",
    "input_path = \"origin\"\n",
    "output_path = \"utf-8\"\n",
    "processor = FileProcessor(input_path, output_path)\n",
    "\n",
    "processor.process_file = file_txt_encoding_to_utf8\n",
    "\n",
    "processor.process_files_multithreaded(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "class MulitProcessingFileProcessor:\n",
    "    \n",
    "    def __init__(self, input_path, output_path):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "    \n",
    "    def get_all_files(self, new_ext = None):\n",
    "        files = []\n",
    "        for dirpath, _, filenames in os.walk(self.input_path):\n",
    "            for filename in filenames:\n",
    "                input_file_path = os.path.join(dirpath, filename)\n",
    "                relative_path = os.path.relpath(input_file_path, self.input_path)\n",
    "                if new_ext is not None and new_ext != \"\":\n",
    "                    root, _ = os.path.splitext(relative_path)\n",
    "                    output_file_path = os.path.join(self.output_path, root + new_ext)\n",
    "                else:\n",
    "                    output_file_path = os.path.join(self.output_path, relative_path)\n",
    "\n",
    "                files.append((input_file_path, output_file_path))\n",
    "        return files\n",
    "    \n",
    "    def process_file(self, paths):\n",
    "        pass\n",
    "\n",
    "    def process_files_multiprocessing(self, num_processes, new_ext = None):\n",
    "        files_to_process = self.get_all_files(new_ext)\n",
    "        \n",
    "        with Pool(processes=num_processes) as pool:\n",
    "            pool.map(self.process_file, files_to_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 限Linux，进程数根据cpu物理核数来定\n",
    "input_path = \"origin\"\n",
    "output_path = \"utf-8\"\n",
    "processor = MulitProcessingFileProcessor(input_path, output_path)\n",
    "\n",
    "def pre_process_file(paths):\n",
    "    input_file_path, output_file_path = paths\n",
    "    file_txt_encoding_to_utf8(input_file_path, output_file_path)\n",
    "\n",
    "processor.process_file = pre_process_file\n",
    "\n",
    "processor.process_files_multiprocessing(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查字符编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_utf8_encoding(input_path, file_ext=('.txt', '.csv')):\n",
    "    \"\"\"\n",
    "    遍历input_path下的所有文件，并检查它们是否是UTF-8编码。\n",
    "    返回一个包含所有非UTF-8编码文件名的列表。\n",
    "    \"\"\"\n",
    "    non_utf8_files = []\n",
    "    for dirpath, _, filenames in os.walk(input_path):\n",
    "        for filename in filenames:\n",
    "            if os.path.splitext(filename)[1].lower() in file_ext:\n",
    "                full_input_path = os.path.join(dirpath, filename)\n",
    "                \n",
    "                f_type = check_file_charset(full_input_path)\n",
    "                if f_type and 'encoding' in f_type.keys():\n",
    "                    if f_type['encoding']:\n",
    "                        if f_type['encoding'].lower() != 'utf-8':\n",
    "                            non_utf8_files.append(full_input_path)\n",
    "                            print(f\"Non-UTF8 file: {full_input_path}, Encoding: {f_type['encoding']}\")\n",
    "                    else:\n",
    "                        print(f\"Non-Encoding file: {full_input_path}\")\n",
    "                \n",
    "    \n",
    "    return non_utf8_files\n",
    "\n",
    "def check_file_charset(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return chardet.detect(f.read(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"\"\n",
    "check_utf8_encoding(input_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
